{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "english-intervention",
   "metadata": {},
   "source": [
    "每个RGB输入图像具有  3×h×w  的形状。我们将这个大小为  3  的轴称为 通道（channel） 维度"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "typical-mother",
   "metadata": {},
   "source": [
    "## 1、多输入通道\n",
    "\n",
    "当输入包含多个通道时，需要构造一个与输入数据具有相同输入通道数目的卷积核，以便与输入数据进行互相关运算。假设输入的通道数为  ci ，那么卷积核的输入通道数也需要为  ci  。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "transparent-volunteer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from d2l import torch as d2l\n",
    "import sys\n",
    "sys.path.append('../../CommonFunctions/tools/')\n",
    "import common_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "rising-organizer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in(X, K):\n",
    "    # 先遍历 “X” 和 “K” 的第0个维度（通道维度），再把它们加在一起\n",
    "    return sum(common_tools.corr2d(x, k) for x, k in zip(X, K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dated-capture",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
    "                  [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cooked-afghanistan",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3, 3]), torch.Size([2, 2, 2]))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "surgical-cattle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-retro",
   "metadata": {},
   "source": [
    "## 2、多输出通道\n",
    "\n",
    "在最流行的神经网络架构中，随着神经网络层数的加深，我们常会增加输出通道的维数，通过减少空间分辨率以获得更大的通道深度。\n",
    "\n",
    "直观地说，我们可以将每个通道看作是对不同特征的响应。\n",
    "\n",
    "而现实可能更为复杂一些，因为每个通道不是独立学习的，而是为了共同使用而优化的。因此，多输出通道并不仅是学习多个单通道的检测器。\n",
    "\n",
    "卷积核的形状是  co×ci×kh×kw "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "anticipated-favorite",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "documentary-natural",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2, 2])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = torch.stack((K, K +1, K + 2), 0)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dental-movie",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0., 1.],\n",
       "          [2., 3.]],\n",
       "\n",
       "         [[1., 2.],\n",
       "          [3., 4.]]],\n",
       "\n",
       "\n",
       "        [[[1., 2.],\n",
       "          [3., 4.]],\n",
       "\n",
       "         [[2., 3.],\n",
       "          [4., 5.]]],\n",
       "\n",
       "\n",
       "        [[[2., 3.],\n",
       "          [4., 5.]],\n",
       "\n",
       "         [[3., 4.],\n",
       "          [5., 6.]]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "expected-group",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 56.,  72.],\n",
       "         [104., 120.]],\n",
       "\n",
       "        [[ 76., 100.],\n",
       "         [148., 172.]],\n",
       "\n",
       "        [[ 96., 128.],\n",
       "         [192., 224.]]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coordinate-founder",
   "metadata": {},
   "source": [
    "## 3、1x1 卷积层\n",
    "因为使用了最小窗口， 1×1  卷积失去了卷积层的特有能力——在高度和宽度维度上，识别相邻元素间相互作用的能力。 而  1×1  卷积的唯一计算发生在通道上。\n",
    "\n",
    "我们可以将  1×1  卷积层看作是在每个像素位置应用的全连接层，以  ci  个输入值转换为  co  个输出值。 因为这仍然是一个卷积层，所以跨像素的权重是一致的。 同时， 1×1  卷积层需要的权重维度为  co×ci  ，再额外加上一个偏置。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-specialist",
   "metadata": {},
   "source": [
    "使用全连接层实现  1×1  卷积。 请注意，我们需要对输入和输出的数据形状进行微调。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "forbidden-sphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.reshape((c_i, h * w))\n",
    "    K = K.reshape((c_o, c_i))\n",
    "    # 全连接层中的矩阵乘法\n",
    "    Y = torch.matmul(K, X)\n",
    "    return Y.reshape((c_o, h, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "sporting-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.normal(0, 1, (3, 3, 3))\n",
    "K = torch.normal(0, 1, (2, 3, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "remarkable-school",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 3, 3]), torch.Size([2, 3, 1, 1]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "demonstrated-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 当执行  1×1  卷积运算时，上述函数相当于先前实现的互相关函数corr2d_multi_in_out。\n",
    "Y1 = corr2d_multi_in_out_1x1(X, K)\n",
    "Y2 = corr2d_multi_in_out(X, K)\n",
    "assert float(torch.abs(Y1 - Y2).sum()) < 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "prostate-coupon",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
