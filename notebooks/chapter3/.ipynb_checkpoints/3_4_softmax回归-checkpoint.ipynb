{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "tamil-monitor",
   "metadata": {},
   "source": [
    "# softmax回归"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sharp-strand",
   "metadata": {},
   "source": [
    "## 1、分类问题\n",
    "\n",
    "统计学家很早以前就发明了一种表示分类数据的简单方法：独热编码（one-hot encoding）。独热编码是一个向量，它的分量和类别一样多。类别对应的分量设置为1，其他所有分量设置为0。 在我们的例子中，标签  y  将是一个三维向量，其中  (1,0,0)  对应于 “猫”、 (0,1,0)  对应于 “鸡”、 (0,0,1)  对应于 “狗”"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-vitamin",
   "metadata": {},
   "source": [
    "## 2、网络结构"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "south-yellow",
   "metadata": {},
   "source": [
    "## 3、全连接的参数开销\n",
    "\n",
    "全连接层：d个输入、q个输出，参数开销O(dq)。\n",
    "\n",
    "将 d 个输入转换为 q 个输出的成本可以减少到 O(dqn) ，其中超参数 n 可以由我们灵活指定。 ？？？？？？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bound-transparency",
   "metadata": {},
   "source": [
    "## 4、softmax 运算\n",
    "\n",
    "采取的主要方法是将模型的输出视作为概率。\n",
    "\n",
    "要将输出视为概率，我们必须保证在任何数据上的输出都是非负的且总和为1。\n",
    "\n",
    "尽管softmax是一个非线性函数，但softmax回归的输出仍然由输入特征的仿射变换决定。因此，softmax回归是一个线性模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sapphire-arkansas",
   "metadata": {},
   "source": [
    "## 5、小批量样本的矢量化\n",
    "\n",
    "为了提高计算效率并且充分利用GPU，我们通常会针对小批量数据执行矢量计算。也就是通常使用的batch size。这样可以加快矩阵-向量乘法。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-romania",
   "metadata": {},
   "source": [
    "## 6、损失函数\n",
    "\n",
    "损失函数度量预测概率的效果。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "changed-rebound",
   "metadata": {},
   "source": [
    "### 对数似然\n",
    "\n",
    "交叉熵损失：预测的概率对应i的真实值为1， 其他为0。所以预测值越接近1， log越大（从-1越接近0），-log越小。损失减小方向。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "behavioral-newport",
   "metadata": {},
   "source": [
    "### softmax及其导数\n",
    "\n",
    "需要手动推导一下？？？"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cutting-float",
   "metadata": {},
   "source": [
    "### 交叉熵损失"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "restricted-independence",
   "metadata": {},
   "source": [
    "## 7、信息论基础"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "curious-double",
   "metadata": {},
   "source": [
    "### 熵\n",
    "1-j求和-P(j)logP(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "organized-identification",
   "metadata": {},
   "source": [
    "## 8、模型预测和评估\n",
    "\n",
    "准确率等于正确预测数与预测的总数之间的比率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grave-dollar",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
